{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErvinHalimsurya/bangkit-capstone-ocr/blob/main/OCR_text_detection_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxmOTI4KTRcD"
      },
      "outputs": [],
      "source": [
        "from imutils.object_detection import non_max_suppression\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import paths\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZw6yFTVTVdB",
        "outputId": "012602c9-e58e-49f4-f93b-e896df351350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'opencv-text-detection'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 11\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dilhelh/opencv-text-detection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkVkelnOTanI",
        "outputId": "5f992379-e94a-48de-d0bd-2a3a2b32e2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading EAST text detector...\n",
            "[INFO] text detection took 0.561433 seconds\n",
            ": cannot connect to X server \n"
          ]
        }
      ],
      "source": [
        "!python /content/opencv-text-detection/text_detection.py --image /content/opencv-text-detection/images/lebron_james.jpg \\\n",
        "\t--east /content/opencv-text-detection/frozen_east_text_detection.pb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX5EP60DTlhE"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite/releases/download/v0.11.0/coco_text_100.tar.gz\n",
        "!tar xf coco_text_100.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkWTWpnKUKx4"
      },
      "outputs": [],
      "source": [
        "IMAGE_LIST = list(paths.list_images('/content/coco_text_100'))\n",
        "IMG_SIZE = 320"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kaHNI0BUOHA"
      },
      "outputs": [],
      "source": [
        "def representative_dataset_gen():\n",
        "    for image_path in IMAGE_LIST:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "        image = image.astype(\"float32\")\n",
        "        mean = np.array([123.68, 116.779, 103.939][::-1], dtype=\"float32\")\n",
        "        image -= mean\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        yield [image]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqI_W6pGUQxT",
        "outputId": "4231b3b2-2644-4ef1-cf0d-6077b752482e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48150544"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "quantization = \"dr\" #@param [\"dr\", \"int8\", \"float16\"]\n",
        "converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\n",
        "    graph_def_file='/content/opencv-text-detection/frozen_east_text_detection.pb', \n",
        "    input_arrays=['input_images'],\n",
        "    output_arrays=['feature_fusion/Conv_7/Sigmoid', 'feature_fusion/concat_3'],\n",
        "    input_shapes={'input_images': [1, 320, 320, 3]}\n",
        ")\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "if quantization==\"float16\":\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "elif quantization==\"int8\":\n",
        "    converter.representative_dataset = representative_dataset_gen\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.uint8\n",
        "    converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open('TextDetection_Model_{}.tflite'.format(quantization), 'wb').write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8q6sx-_VVsR"
      },
      "outputs": [],
      "source": [
        "# define the two output layer names for the EAST detector model that\n",
        "# we are interested -- the first is the output probabilities and the\n",
        "# second can be used to derive the bounding box coordinates of text\n",
        "layerNames = [\n",
        "    \"feature_fusion/Conv_7/Sigmoid\",\n",
        "    \"feature_fusion/concat_3\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3zH-9SdUTBI",
        "outputId": "5c18f44b-fed4-4017-e42d-afd3c85ab035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 24M Jun 12 14:10 TextDetection_Model_dr.tflite\n",
            "-rw-r--r-- 1 root root 46M Jun 12 14:11 TextDetection_Model_float16.tflite\n",
            "-rw-r--r-- 1 root root 24M Jun 12 14:10 TextDetection_Model_int8.tflite\n",
            "-rw-r--r-- 1 root root 93M Jun 12 14:09 /content/opencv-text-detection/frozen_east_text_detection.pb\n"
          ]
        }
      ],
      "source": [
        "!ls -lh *.tflite\n",
        "!ls -lh /content/opencv-text-detection/frozen_east_text_detection.pb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "OCR text detection_ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmcLUsjtYsaqpeMDBn/Duq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}